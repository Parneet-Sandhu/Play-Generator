{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19343f06f3034fcea99e8643e44e59f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Hero",
              "Villain",
              "Sidekick"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Character:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_84998ea93061494e9739c29f87b01096",
            "style": "IPY_MODEL_25807a4c394944748ddf93579c9fb756"
          }
        },
        "84998ea93061494e9739c29f87b01096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25807a4c394944748ddf93579c9fb756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "665a5ad37cb148e78a11a23cf610cf04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Generate Play",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_1ba26587493d4a8887fa2ddda84480a7",
            "style": "IPY_MODEL_1b90b5084d6f4f639e3c6990bc63b37a",
            "tooltip": ""
          }
        },
        "1ba26587493d4a8887fa2ddda84480a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b90b5084d6f4f639e3c6990bc63b37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a48db7be55fd4743a8ecf4e54ebf54b4": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9799968d62d3470ba3c2a873df5e1733",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Generated play with character: Hero\n"
                ]
              }
            ]
          }
        },
        "9799968d62d3470ba3c2a873df5e1733": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dax6aJMt3kQ2"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file=tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpnViXTa4MQ1",
        "outputId": "5527a8d9-b1ed-4f76-f4c7-b9ff959c3318"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LnA8KpW4U-n",
        "outputId": "7156aac0-5abf-4b24-87c6-e2427324366d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ2ocRNJ4zqj",
        "outputId": "36982cd8-bee5-431a-8a26-903cc88f7396"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encoding**"
      ],
      "metadata": {
        "id": "2T7GDh0747np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int = text_to_int(text)"
      ],
      "metadata": {
        "id": "jApPCVeJ46r2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Text:\", text[:13])\n",
        "print(\"Encoded:\", text_to_int(text[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9aH52Sr5JIe",
        "outputId": "01f8ae4b-b8eb-4d4a-809a-471bba1b0db2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: First Citizen\n",
            "Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx2char[ints])\n",
        "\n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiAU50DZ5YJT",
        "outputId": "ae9d733d-a715-429d-8481-7452d641ef0b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Training Examples**"
      ],
      "metadata": {
        "id": "il0UW8Oz5_Kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100  # length of sequence for a training example\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "metadata": {
        "id": "4r6o5Qrz6OLE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "9x_MOSdC6dJM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "cnBmrNME6lGO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in dataset.take(2):\n",
        "  print(\"\\n\\nEXAMPLE\\n\")\n",
        "  print(\"INPUT\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"\\nOUTPUT\")\n",
        "  print(int_to_text(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn98-Xs36ytO",
        "outputId": "cd077940-b984-4efc-d84b-8597040a2d20"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "\n",
            "OUTPUT\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "\n",
            "OUTPUT\n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "aZicY6Xo7ZkU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building The Model**"
      ],
      "metadata": {
        "id": "lJiavSS97je0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  model.build(input_shape=(BATCH_SIZE, None))\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "uw8U7iFB7pYA",
        "outputId": "0d4488e6-db94-43bf-c6f6-cab6a043de4f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │          \u001b[38;5;34m16,640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │       \u001b[38;5;34m5,246,976\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)              │          \u001b[38;5;34m66,625\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,976</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,625</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,330,241\u001b[0m (20.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,330,241</span> (20.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,330,241\u001b[0m (20.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,330,241</span> (20.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating a Loss Function**"
      ],
      "metadata": {
        "id": "oUzY8ENbUlHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYWseeRyUuPp",
        "outputId": "c8747c37-0aed-4ae4-f77a-f71ef931aa41"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9sv3WCBVDJS",
        "outputId": "bf2df9b6-b768-4150-a303-9cae4d8b7df6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[ 9.62107326e-04  2.55238777e-03  2.58322136e-04 ... -4.90181986e-03\n",
            "   -1.02858001e-03 -1.32022717e-04]\n",
            "  [ 1.03366352e-03  1.31895591e-03  6.09934237e-03 ... -8.75646062e-03\n",
            "   -2.99333537e-04 -3.05108656e-03]\n",
            "  [-5.76223386e-03  2.04400299e-03 -6.29303162e-04 ... -6.71098009e-03\n",
            "    2.77748739e-04 -4.35758056e-03]\n",
            "  ...\n",
            "  [-6.03024149e-03  7.98759423e-03  4.86178510e-03 ... -8.23707506e-03\n",
            "    2.50611478e-03 -3.58765852e-03]\n",
            "  [-5.26363729e-03  5.38189663e-03  1.67782826e-03 ... -7.35613843e-03\n",
            "    3.71264364e-03 -5.52970264e-03]\n",
            "  [-1.81063428e-03  7.16607505e-03  3.10018822e-03 ... -1.01285353e-02\n",
            "    3.15599586e-03 -3.85666382e-03]]\n",
            "\n",
            " [[ 4.50026570e-03 -5.43750683e-03  2.89326487e-03 ...  3.82275949e-03\n",
            "   -9.76037700e-04  4.29864886e-04]\n",
            "  [ 6.55702432e-04 -8.04024166e-04 -2.70096725e-03 ...  7.66490411e-04\n",
            "   -1.74408767e-03 -7.57852511e-04]\n",
            "  [-6.90737460e-03  8.35402228e-04 -8.83037131e-03 ...  1.35483034e-03\n",
            "   -1.26926997e-03 -2.83379829e-03]\n",
            "  ...\n",
            "  [-7.49669224e-03  5.10699698e-04 -1.10764485e-02 ...  2.41019600e-03\n",
            "   -2.27525202e-03 -3.01847840e-03]\n",
            "  [-2.63106474e-03 -2.03055679e-03 -9.39681288e-03 ...  2.90644728e-03\n",
            "   -3.22130811e-03 -5.46497386e-03]\n",
            "  [-5.29305683e-03  2.62582535e-03 -3.70822824e-03 ... -1.63923530e-03\n",
            "   -3.13357706e-03 -2.72642984e-03]]\n",
            "\n",
            " [[-2.44063165e-04 -2.01851851e-03  2.87519954e-03 ...  1.09292637e-03\n",
            "    7.13763339e-03  1.00205350e-03]\n",
            "  [-5.11949370e-03  3.07085994e-03  5.02303615e-03 ... -1.71190687e-03\n",
            "    4.15066350e-03  1.84568879e-03]\n",
            "  [-6.43198332e-03 -1.92852609e-03 -2.10559694e-03 ... -1.54432177e-03\n",
            "    6.65173109e-04  2.70309625e-03]\n",
            "  ...\n",
            "  [ 6.20832958e-04 -2.50871503e-03 -2.16370355e-03 ... -5.85939211e-04\n",
            "   -1.66017620e-03 -4.10736399e-03]\n",
            "  [ 2.17399909e-03 -1.86366308e-03  5.76319778e-03 ... -3.57712386e-03\n",
            "    2.25680356e-04 -6.74544694e-03]\n",
            "  [ 5.64656500e-03  2.18975893e-03  6.27293577e-03 ...  1.22444856e-03\n",
            "    2.82233232e-04 -4.67557507e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-2.96622573e-04 -9.89492983e-05 -2.82067526e-03 ...  5.43763302e-03\n",
            "   -9.14882985e-04 -1.51499713e-04]\n",
            "  [ 3.83839128e-03 -4.89245635e-04 -5.15676523e-03 ...  3.14611266e-03\n",
            "   -2.58147903e-03 -2.39732349e-03]\n",
            "  [ 6.49781432e-03 -2.40314007e-03 -2.16230378e-03 ...  7.23590783e-04\n",
            "   -3.95522872e-03 -3.46357631e-03]\n",
            "  ...\n",
            "  [-7.01487716e-03  2.18112115e-03 -4.58742445e-03 ...  2.63335207e-03\n",
            "    5.98378526e-03 -8.19054316e-04]\n",
            "  [-3.56991496e-03  1.57993124e-03  3.28209694e-03 ... -2.15763925e-03\n",
            "    5.63276000e-03 -3.75616108e-03]\n",
            "  [-7.33330846e-04  3.90860485e-03  4.13045520e-03 ... -5.74607309e-03\n",
            "    4.39129910e-03 -2.82670837e-03]]\n",
            "\n",
            " [[ 2.57175649e-04  1.14120706e-03  2.85150460e-03 ... -2.91392091e-03\n",
            "   -2.44292401e-04  1.57863030e-03]\n",
            "  [ 1.06666493e-03 -9.02440283e-04  3.10143013e-03 ...  3.78650875e-04\n",
            "    1.45800214e-03  4.75808140e-03]\n",
            "  [ 1.86307949e-03  1.96642432e-04  4.14373260e-03 ... -1.03210506e-03\n",
            "    2.92217097e-04  4.08910029e-03]\n",
            "  ...\n",
            "  [ 4.13854839e-04  1.27675140e-03  4.94886376e-03 ... -3.48569080e-03\n",
            "    3.84055800e-03 -1.00356247e-03]\n",
            "  [-4.89661517e-03  3.01423832e-03 -1.95285853e-03 ... -1.52290799e-03\n",
            "    3.57620558e-03 -3.77990725e-03]\n",
            "  [-6.41327351e-03  6.99790055e-03  3.27216624e-03 ... -2.92814802e-03\n",
            "    2.45776400e-03 -1.63945276e-03]]\n",
            "\n",
            " [[-6.56373333e-03  1.56106614e-03 -6.06882572e-03 ... -1.20277900e-06\n",
            "   -2.34671334e-05 -2.59840162e-03]\n",
            "  [ 2.84216978e-04  1.95633573e-03 -2.84557114e-03 ... -1.12976343e-03\n",
            "    1.13174948e-03 -1.99620659e-03]\n",
            "  [-6.43266411e-03  1.89894158e-03 -6.72231382e-03 ... -5.36228181e-04\n",
            "    1.32375653e-03 -3.36962286e-03]\n",
            "  ...\n",
            "  [ 1.05628865e-02  8.82071629e-03  1.94605403e-02 ... -4.42320853e-03\n",
            "    3.59112886e-03 -2.49724812e-03]\n",
            "  [ 1.32467030e-02  3.28221754e-03  1.63844395e-02 ... -1.12834841e-03\n",
            "    4.82605258e-03 -1.02781823e-05]\n",
            "  [ 9.89328977e-03  6.33821543e-03  2.07392499e-02 ... -3.75874061e-03\n",
            "    7.01638777e-03 -2.53171404e-03]]], shape=(64, 100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred=example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzuXtRv2VJ6U",
        "outputId": "7c439e1b-5aa5-410d-9916-6c5f13c7c3f3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[ 0.00096211  0.00255239  0.00025832 ... -0.00490182 -0.00102858\n",
            "  -0.00013202]\n",
            " [ 0.00103366  0.00131896  0.00609934 ... -0.00875646 -0.00029933\n",
            "  -0.00305109]\n",
            " [-0.00576223  0.002044   -0.0006293  ... -0.00671098  0.00027775\n",
            "  -0.00435758]\n",
            " ...\n",
            " [-0.00603024  0.00798759  0.00486179 ... -0.00823708  0.00250611\n",
            "  -0.00358766]\n",
            " [-0.00526364  0.0053819   0.00167783 ... -0.00735614  0.00371264\n",
            "  -0.0055297 ]\n",
            " [-0.00181063  0.00716608  0.00310019 ... -0.01012854  0.003156\n",
            "  -0.00385666]], shape=(100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_pred=pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-gnqlnvVmEk",
        "outputId": "55074eae-5c8e-4edf-f4f6-41058c490b33"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[ 0.00096211  0.00255239  0.00025832 -0.00143754 -0.00265632  0.00058506\n",
            " -0.00161378  0.00223959 -0.00099285  0.008294    0.00227467 -0.00275118\n",
            " -0.00096078  0.0044377  -0.00672495  0.00207169  0.00113936  0.00202321\n",
            "  0.00128931  0.00158908  0.00423499 -0.00753006 -0.00180641  0.00290694\n",
            "  0.00072775  0.00306131  0.00255815 -0.00182416  0.00385401 -0.00108789\n",
            " -0.00417412 -0.002959   -0.00722601  0.00146578  0.00512989 -0.0008711\n",
            " -0.00204008  0.00029567 -0.00504463  0.0003568  -0.00603109  0.00491444\n",
            " -0.00501671 -0.00290687  0.00653206  0.00019825  0.00068665  0.00094066\n",
            "  0.00183978 -0.000749    0.0017769  -0.00227429  0.0016972  -0.00094775\n",
            "  0.00389626 -0.00587823  0.00557587  0.00245275  0.00060527 -0.00115768\n",
            "  0.00176803 -0.00012672 -0.00490182 -0.00102858 -0.00013202], shape=(65,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices=tf.random.categorical(pred,num_samples=1)\n",
        "sampled_indices=np.reshape(sampled_indices,(1, -1))[0]\n",
        "predicted_chars=int_to_text(sampled_indices)\n",
        "predicted_chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-pUFdN5oVwv_",
        "outputId": "cadbb7ab-6787-47e6-89da-7d24db93167b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\",A\\n!nY-rkpVZh!S?UlYi\\nzRtIvItA;WRbA?lCMSjjOnfLANgkc$k,VTdq-AC!w3W3,!h.YQfTxyGaLWe$rmr'GaDLC3FDb\\nHic3q\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "metadata": {
        "id": "GkljNvD1Z57J"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compiling the Model**"
      ],
      "metadata": {
        "id": "a46GpCr5aG8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "TblUIQaGaCNG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Checkpoints**"
      ],
      "metadata": {
        "id": "47KHiH6HaS57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoints_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoints_dir, \"ckpt_{epoch}.weights.h5\") # Add '.weights.h5' to the filename\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "XbzOjmWFaZhy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "qWQDTdKrbXA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpv-soHpbZHr",
        "outputId": "33d7c181-05e3-4012-ecf3-fd73aeefee45"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 72ms/step - loss: 2.8513\n",
            "Epoch 2/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 1.8527\n",
            "Epoch 3/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - loss: 1.5987\n",
            "Epoch 4/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 75ms/step - loss: 1.4764\n",
            "Epoch 5/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 82ms/step - loss: 1.3995\n",
            "Epoch 6/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 81ms/step - loss: 1.3465\n",
            "Epoch 7/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 78ms/step - loss: 1.3052\n",
            "Epoch 8/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 1.2664\n",
            "Epoch 9/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 1.2324\n",
            "Epoch 10/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 1.2014\n",
            "Epoch 11/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 84ms/step - loss: 1.1687\n",
            "Epoch 12/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 81ms/step - loss: 1.1379\n",
            "Epoch 13/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 77ms/step - loss: 1.1018\n",
            "Epoch 14/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 1.0694\n",
            "Epoch 15/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 78ms/step - loss: 1.0347\n",
            "Epoch 16/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - loss: 1.0008\n",
            "Epoch 17/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.9654\n",
            "Epoch 18/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.9282\n",
            "Epoch 19/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 77ms/step - loss: 0.8933\n",
            "Epoch 20/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.8566\n",
            "Epoch 21/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 0.8234\n",
            "Epoch 22/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 77ms/step - loss: 0.7871\n",
            "Epoch 23/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.7570\n",
            "Epoch 24/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 0.7253\n",
            "Epoch 25/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 77ms/step - loss: 0.6986\n",
            "Epoch 26/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.6746\n",
            "Epoch 27/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.6479\n",
            "Epoch 28/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.6262\n",
            "Epoch 29/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.6081\n",
            "Epoch 30/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.5865\n",
            "Epoch 31/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.5710\n",
            "Epoch 32/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.5562\n",
            "Epoch 33/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 78ms/step - loss: 0.5403\n",
            "Epoch 34/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.5287\n",
            "Epoch 35/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.5169\n",
            "Epoch 36/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.5048\n",
            "Epoch 37/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.4931\n",
            "Epoch 38/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.4879\n",
            "Epoch 39/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.4798\n",
            "Epoch 40/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.4712\n",
            "Epoch 41/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 77ms/step - loss: 0.4635\n",
            "Epoch 42/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 77ms/step - loss: 0.4583\n",
            "Epoch 43/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 77ms/step - loss: 0.4513\n",
            "Epoch 44/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.4464\n",
            "Epoch 45/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.4421\n",
            "Epoch 46/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.4355\n",
            "Epoch 47/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 79ms/step - loss: 0.4352\n",
            "Epoch 48/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 82ms/step - loss: 0.4298\n",
            "Epoch 49/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 78ms/step - loss: 0.4240\n",
            "Epoch 50/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 79ms/step - loss: 0.4227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
      ],
      "metadata": {
        "id": "aWLupUlBbyc4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume you want to load the checkpoint from epoch 50, modify the filename accordingly\n",
        "checkpoint_path = os.path.join(checkpoints_dir, \"ckpt_50.weights.h5\")\n",
        "\n",
        "# Create a new model instance with the desired batch_size (1 in this case)\n",
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)\n",
        "\n",
        "# Load weights directly using the checkpoint path\n",
        "model.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "uLHGAOukb1Hn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_num = 10\n",
        "# Use keras.models.load_model to load the entire model along with the architecture\n",
        "# or model.load_weights to load the weights alone.\n",
        "checkpoint_path = os.path.join(checkpoints_dir, \"ckpt_\" + str(checkpoint_num) + \".weights.h5\")\n",
        "model.load_weights(checkpoint_path)  # Assuming 'model' is already built\n",
        "# model.build(tf.TensorShape([1, None]))  # No need to build if using load_model"
      ],
      "metadata": {
        "id": "N2H34lswb4wF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "  num_generate = 800\n",
        "\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        "  temperature= 1.0\n",
        "\n",
        "  # Remove or comment out the following line:\n",
        "  # model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "    predictions= model(input_eval)\n",
        "    # The problem lies here. You are trying to squeeze dimension 0,\n",
        "    # which has size 64 (batch size). Instead, you should be selecting\n",
        "    # the first prediction from the batch using predictions[0]\n",
        "    # predictions = tf.squeeze(predictions, 0)  # This line causes the error\n",
        "    predictions = predictions[0]  # Select the first (and only) prediction from the batch\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "  return(start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "rHp7s95dchYz"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp= input(\"Type a starting string: \")\n",
        "print(generate_text(model, inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8DBOGEFgfXm",
        "outputId": "faba0ba2-810d-4e7d-bef4-d44ff3985731"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type a starting string: venice\n",
            "venice\n",
            "Than what the flood of such a shrpendain reverend blood estables?--farewell.\n",
            "\n",
            "GLOUCESTER:\n",
            "My lord, Signior Gremio: there at this old\n",
            "You must thy exflenge; not ambriaring\n",
            "Her head in office, your mistake masse:\n",
            "Mercy what so farmimy\n",
            "Are not worn you tell you, achor the present battle.\n",
            "\n",
            "Second Murderer:\n",
            "Why, seek her not with curs and rdy\n",
            "On resoluting a nipe the other, nath, it.\n",
            "Thy night-new days not hate such edgects do this man\n",
            "never report to please.\n",
            "\n",
            "MENENIUS:\n",
            "O woo'd to-morrow, not? the Antigones\n",
            "Do could till you affair that I have leave them,\n",
            "well all the first of womf in Coriolanus;\n",
            "And whose suspicition of you of an ill clroud-ear,\n",
            "That is a harm action: good my dear lords. Come,\n",
            "Now claudio, thy lifes that were king, such as if, and ask.\n",
            "CHEMARD II:\n",
            "We lend them here and thy sl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Define function for play generator (example)\n",
        "def generate_play(character_type):\n",
        "    return f\"Generated play with character: {character_type}\"\n",
        "\n",
        "# Create interactive widgets\n",
        "character_selector = widgets.Dropdown(\n",
        "    options=['Hero', 'Villain', 'Sidekick'],\n",
        "    description='Character:'\n",
        ")\n",
        "\n",
        "generate_button = widgets.Button(description=\"Generate Play\")\n",
        "output = widgets.Output()\n",
        "\n",
        "# Define button click behavior\n",
        "def on_button_click(b):\n",
        "    with output:\n",
        "        print(generate_play(character_selector.value))\n",
        "\n",
        "# Attach button click event\n",
        "generate_button.on_click(on_button_click)\n",
        "\n",
        "# Display widgets\n",
        "display(character_selector, generate_button, output)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "19343f06f3034fcea99e8643e44e59f9",
            "84998ea93061494e9739c29f87b01096",
            "25807a4c394944748ddf93579c9fb756",
            "665a5ad37cb148e78a11a23cf610cf04",
            "1ba26587493d4a8887fa2ddda84480a7",
            "1b90b5084d6f4f639e3c6990bc63b37a",
            "a48db7be55fd4743a8ecf4e54ebf54b4",
            "9799968d62d3470ba3c2a873df5e1733"
          ]
        },
        "id": "-hbbREpdpbgA",
        "outputId": "920ab827-3065-4479-d136-b5d6b1019688"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Character:', options=('Hero', 'Villain', 'Sidekick'), value='Hero')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19343f06f3034fcea99e8643e44e59f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Generate Play', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "665a5ad37cb148e78a11a23cf610cf04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a48db7be55fd4743a8ecf4e54ebf54b4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model weights\n",
        "model.save_weights('play_generator_weights.weights.h5')"
      ],
      "metadata": {
        "id": "_WoPLi35qowz"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}